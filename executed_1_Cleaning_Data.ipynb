{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff34956a0a5b68d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:12:58.124271Z",
     "start_time": "2025-07-20T20:12:54.648754Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-20T20:15:06.187645Z",
     "iopub.status.busy": "2025-07-20T20:15:06.187645Z",
     "iopub.status.idle": "2025-07-20T20:15:07.745033Z",
     "shell.execute_reply": "2025-07-20T20:15:07.745033Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Pranay\n",
      "[nltk_data]     Malhotra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Pranay\n",
      "[nltk_data]     Malhotra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download required NLTK data (only needs to be run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d42b41460d23399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:12:58.400473Z",
     "start_time": "2025-07-20T20:12:58.392392Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-20T20:15:07.748430Z",
     "iopub.status.busy": "2025-07-20T20:15:07.747743Z",
     "iopub.status.idle": "2025-07-20T20:15:07.750910Z",
     "shell.execute_reply": "2025-07-20T20:15:07.750910Z"
    }
   },
   "outputs": [],
   "source": [
    "# Folder where transcripts are stored\n",
    "data_folder = \"data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b24f2e4d27279bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:12:58.567607Z",
     "start_time": "2025-07-20T20:12:58.548307Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-20T20:15:07.750910Z",
     "iopub.status.busy": "2025-07-20T20:15:07.750910Z",
     "iopub.status.idle": "2025-07-20T20:15:07.756678Z",
     "shell.execute_reply": "2025-07-20T20:15:07.756678Z"
    }
   },
   "outputs": [],
   "source": [
    "# line loads a list of common English stop words from NLTK and stores them in a Python set called stop_words.\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff03b3904888e19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:12:58.614947Z",
     "start_time": "2025-07-20T20:12:58.609385Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-20T20:15:07.759058Z",
     "iopub.status.busy": "2025-07-20T20:15:07.759058Z",
     "iopub.status.idle": "2025-07-20T20:15:07.762880Z",
     "shell.execute_reply": "2025-07-20T20:15:07.762880Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Simple tokenization (split by whitespace)\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Remove stopwords and non-alphabetic tokens\n",
    "    cleaned_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "    return \" \".join(cleaned_tokens), cleaned_tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59dc3e115a00cdc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:12:58.696126Z",
     "start_time": "2025-07-20T20:12:58.658602Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-20T20:15:07.762880Z",
     "iopub.status.busy": "2025-07-20T20:15:07.762880Z",
     "iopub.status.idle": "2025-07-20T20:15:07.800156Z",
     "shell.execute_reply": "2025-07-20T20:15:07.800156Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:/Users/Pranay\n",
      "[nltk_data]     Malhotra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Clean download\n",
    "nltk.download('punkt', download_dir='C:/Users/Pranay Malhotra/nltk_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdcf817dfc7be69f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:12:58.844756Z",
     "start_time": "2025-07-20T20:12:58.753424Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-20T20:15:07.800156Z",
     "iopub.status.busy": "2025-07-20T20:15:07.800156Z",
     "iopub.status.idle": "2025-07-20T20:15:07.828561Z",
     "shell.execute_reply": "2025-07-20T20:15:07.828032Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize list to store cleaned data\n",
    "all_data = []\n",
    "\n",
    "# Loop over all .txt files in data folder\n",
    "for file_name in os.listdir(data_folder):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        comedian_name = file_name.replace(\".txt\", \"\")\n",
    "        with open(os.path.join(data_folder, file_name), \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "            cleaned_text, tokens = clean_text(content)\n",
    "            all_data.append({\n",
    "                \"comedian\": comedian_name,\n",
    "                \"original_text\": content,\n",
    "                \"cleaned_text\": cleaned_text,\n",
    "                \"tokens\": tokens\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ccc52b8048451b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:12:58.878838Z",
     "start_time": "2025-07-20T20:12:58.861044Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-20T20:15:07.828561Z",
     "iopub.status.busy": "2025-07-20T20:15:07.828561Z",
     "iopub.status.idle": "2025-07-20T20:15:07.834750Z",
     "shell.execute_reply": "2025-07-20T20:15:07.834750Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert list of dictionaries to pandas DataFrame\n",
    "df = pd.DataFrame(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3354999e60b231f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:12:58.942538Z",
     "start_time": "2025-07-20T20:12:58.925375Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-20T20:15:07.837875Z",
     "iopub.status.busy": "2025-07-20T20:15:07.837875Z",
     "iopub.status.idle": "2025-07-20T20:15:07.849434Z",
     "shell.execute_reply": "2025-07-20T20:15:07.849434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comedian</th>\n",
       "      <th>original_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kenny</td>\n",
       "      <td>You guys are the positive audience. Okay? Ther...</td>\n",
       "      <td>guys positive audience okay positive audience ...</td>\n",
       "      <td>[guys, positive, audience, okay, positive, aud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urooj</td>\n",
       "      <td>Are you guys aware of the cameras? Are you fee...</td>\n",
       "      <td>guys aware cameras feeling conscious cameras c...</td>\n",
       "      <td>[guys, aware, cameras, feeling, conscious, cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>varun</td>\n",
       "      <td>Are you ready?\\n\\nAre you excited?\\n\\nSo put y...</td>\n",
       "      <td>ready excited put hands together welcome stage...</td>\n",
       "      <td>[ready, excited, put, hands, together, welcome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virdas1</td>\n",
       "      <td>I lost 80% of my mind. It’s very freeing. You ...</td>\n",
       "      <td>lost mind freeing see look faces right way oh ...</td>\n",
       "      <td>[lost, mind, freeing, see, look, faces, right,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virdas2</td>\n",
       "      <td>[Vir Das] What you’re about to watch wasn’t su...</td>\n",
       "      <td>vir das watch supposed happen completely unscr...</td>\n",
       "      <td>[vir, das, watch, supposed, happen, completely...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comedian                                      original_text  \\\n",
       "0    kenny  You guys are the positive audience. Okay? Ther...   \n",
       "1    urooj  Are you guys aware of the cameras? Are you fee...   \n",
       "2    varun  Are you ready?\\n\\nAre you excited?\\n\\nSo put y...   \n",
       "3  virdas1  I lost 80% of my mind. It’s very freeing. You ...   \n",
       "4  virdas2  [Vir Das] What you’re about to watch wasn’t su...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  guys positive audience okay positive audience ...   \n",
       "1  guys aware cameras feeling conscious cameras c...   \n",
       "2  ready excited put hands together welcome stage...   \n",
       "3  lost mind freeing see look faces right way oh ...   \n",
       "4  vir das watch supposed happen completely unscr...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [guys, positive, audience, okay, positive, aud...  \n",
       "1  [guys, aware, cameras, feeling, conscious, cam...  \n",
       "2  [ready, excited, put, hands, together, welcome...  \n",
       "3  [lost, mind, freeing, see, look, faces, right,...  \n",
       "4  [vir, das, watch, supposed, happen, completely...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the cleaned data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6092a312921aa84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:12:59.035266Z",
     "start_time": "2025-07-20T20:12:59.018577Z"
    },
    "execution": {
     "iopub.execute_input": "2025-07-20T20:15:07.849434Z",
     "iopub.status.busy": "2025-07-20T20:15:07.849434Z",
     "iopub.status.idle": "2025-07-20T20:15:07.864889Z",
     "shell.execute_reply": "2025-07-20T20:15:07.864889Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_transcripts.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

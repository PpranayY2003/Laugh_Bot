{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:53:16.416499Z",
     "start_time": "2025-07-20T20:53:16.397894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import Counter\n",
    "\n",
    "df = pd.read_csv(\"cleaned_transcripts.csv\")\n",
    "documents = df[\"cleaned_text\"].dropna().tolist()\n"
   ],
   "id": "7385f4891cfecb84",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:53:16.781520Z",
     "start_time": "2025-07-20T20:53:16.761663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.9, min_df=2, stop_words='english', max_features=5000)\n",
    "X = vectorizer.fit_transform(documents)\n",
    "X_norm = normalize(X)"
   ],
   "id": "ac27b711c3dfcc5e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:53:31.270423Z",
     "start_time": "2025-07-20T20:53:29.715262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_docs = len(documents)\n",
    "num_topics = min(10, num_docs)\n",
    "kmeans = KMeans(n_clusters=num_topics, random_state=42, n_init='auto')\n",
    "labels = kmeans.fit_predict(X_norm)\n"
   ],
   "id": "b77b9a2f41e28516",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:53:45.747695Z",
     "start_time": "2025-07-20T20:53:45.738620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "topic_keywords = []\n",
    "\n",
    "print(f\"\\nüîπ Total topics found: {num_topics}\\n\")\n",
    "for i in range(num_topics):\n",
    "    center = kmeans.cluster_centers_[i]\n",
    "    top_indices = center.argsort()[-5:][::-1]\n",
    "    top_words = [feature_names[j] for j in top_indices]\n",
    "    topic_keywords.append(top_words)\n",
    "    print(f\"üî∏ Topic {i}: {top_words}\")"
   ],
   "id": "93386fa4b6496dc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Total topics found: 5\n",
      "\n",
      "üî∏ Topic 0: ['said', 'therapy', 'therapist', 'men', 'doctor']\n",
      "üî∏ Topic 1: ['shit', 'beautiful', 'world', 'indian', 'india']\n",
      "üî∏ Topic 2: ['jokes', 'bank', 'government', 'scared', 'issues']\n",
      "üî∏ Topic 3: ['laughing', 'gonna', 'man', 'woman', 'shit']\n",
      "üî∏ Topic 4: ['fuck', 'pretty', 'guy', 'seriously', 'tell']\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:54:59.402097Z",
     "start_time": "2025-07-20T20:54:59.395434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "topic_counts = Counter(labels)\n",
    "top_topics = topic_counts.most_common(5)\n",
    "\n",
    "print(\"\\nüîπ Top 5 most common topics across documents:\\n\")\n",
    "for rank, (topic_num, count) in enumerate(top_topics, start=1):\n",
    "    print(f\"üî∏ Rank {rank} ‚Äî Topic {topic_num} : {topic_keywords[topic_num]}\")"
   ],
   "id": "b63a85e6a73385b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Top 5 most common topics across documents:\n",
      "\n",
      "üî∏ Rank 1 ‚Äî Topic 2 : ['jokes', 'bank', 'government', 'scared', 'issues']\n",
      "üî∏ Rank 2 ‚Äî Topic 0 : ['said', 'therapy', 'therapist', 'men', 'doctor']\n",
      "üî∏ Rank 3 ‚Äî Topic 4 : ['fuck', 'pretty', 'guy', 'seriously', 'tell']\n",
      "üî∏ Rank 4 ‚Äî Topic 1 : ['shit', 'beautiful', 'world', 'indian', 'india']\n",
      "üî∏ Rank 5 ‚Äî Topic 3 : ['laughing', 'gonna', 'man', 'woman', 'shit']\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T20:57:24.058386Z",
     "start_time": "2025-07-20T20:57:20.533275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define topic label candidates\n",
    "label_candidates = [\n",
    "    \"Politics\", \"Mental Health\", \"Relationships\", \"Comedy\", \"Culture\", \"Gender\",\n",
    "    \"Religion\", \"Sexuality\", \"Education\", \"Work\", \"Finance\", \"Society\",\n",
    "    \"Science\", \"Parenting\", \"Travel\", \"Technology\"\n",
    "]\n",
    "\n",
    "# Convert label candidates into embeddings\n",
    "label_embeddings = model.encode(label_candidates)\n",
    "\n",
    "# Build topic phrases from keywords\n",
    "topic_phrases = [' '.join(keywords) for keywords in topic_keywords]\n",
    "topic_embeddings = model.encode(topic_phrases)\n",
    "\n",
    "# Match each topic to the best label\n",
    "topic_labels = []\n",
    "for i, emb in enumerate(topic_embeddings):\n",
    "    sims = cosine_similarity([emb], label_embeddings)[0]\n",
    "    best_label = label_candidates[sims.argmax()]\n",
    "    topic_labels.append(best_label)\n",
    "\n",
    "# Print final labeled topics\n",
    "print(\"\\nüè∑Ô∏è Auto-labeled Topics:\\n\")\n",
    "for i, (keywords, label) in enumerate(zip(topic_keywords, topic_labels)):\n",
    "    print(f\"üß© Topic {i} ‚Äî {label}: {keywords}\")\n"
   ],
   "id": "5d9117462628933d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üè∑Ô∏è Auto-labeled Topics:\n",
      "\n",
      "üß© Topic 0 ‚Äî Mental Health: ['said', 'therapy', 'therapist', 'men', 'doctor']\n",
      "üß© Topic 1 ‚Äî Culture: ['shit', 'beautiful', 'world', 'indian', 'india']\n",
      "üß© Topic 2 ‚Äî Comedy: ['jokes', 'bank', 'government', 'scared', 'issues']\n",
      "üß© Topic 3 ‚Äî Gender: ['laughing', 'gonna', 'man', 'woman', 'shit']\n",
      "üß© Topic 4 ‚Äî Sexuality: ['fuck', 'pretty', 'guy', 'seriously', 'tell']\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "74a68239ceb39acf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T05:54:24.807529Z",
     "start_time": "2025-07-20T05:54:24.791133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hdbscan\n",
    "import umap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"cleaned_transcripts.csv\")  # Replace with actual cleaned text file\n",
    "documents = df[\"cleaned_text\"].tolist()\n"
   ],
   "id": "7385f4891cfecb84",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T05:54:25.434253Z",
     "start_time": "2025-07-20T05:54:25.424675Z"
    }
   },
   "cell_type": "code",
   "source": "topic_keywords",
   "id": "c0de19bccf84ddec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T05:54:30.250026Z",
     "start_time": "2025-07-20T05:54:25.567120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Create embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.encode(documents, show_progress_bar=True)\n",
    "\n",
    "n_samples = len(embeddings)\n",
    "\n",
    "# --- Safeguard for extremely small datasets ---\n",
    "if n_samples < 2:\n",
    "    raise ValueError(\"Not enough samples to perform UMAP or HDBSCAN. Need at least 2 documents.\")"
   ],
   "id": "17abbc5b39c490b1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s]\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T05:54:30.287194Z",
     "start_time": "2025-07-20T05:54:30.281850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- HDBSCAN Settings ---\n",
    "# min_cluster_size should be at least 2 for meaningful clusters.\n",
    "# min_samples should typically be less than min_cluster_size.\n",
    "# Adjust these values based on your data size and desired cluster density.\n",
    "# For very small N, you might need to go as low as 2 for min_cluster_size.\n",
    "safe_min_cluster_size = max(2, min(10, n_samples // 4)) # Adjusted to be a bit more flexible for small N\n",
    "safe_min_samples = max(1, min(5, safe_min_cluster_size -1)) # Should be less than min_cluster_size\n",
    "\n",
    "print(f\"HDBSCAN: n_samples={n_samples}, safe_min_cluster_size={safe_min_cluster_size}, safe_min_samples={safe_min_samples}\")\n",
    "\n",
    "hdbscan_model = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=safe_min_cluster_size,\n",
    "    min_samples=safe_min_samples,\n",
    "    metric='euclidean',\n",
    "    prediction_data=True\n",
    ")"
   ],
   "id": "fed0a7c04ebb6a32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDBSCAN: n_samples=5, safe_min_cluster_size=2, safe_min_samples=1\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T05:54:30.336400Z",
     "start_time": "2025-07-20T05:54:30.325675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. n_neighbors: Must be less than n_samples.\n",
    "#    For very small N, setting it to 2 or 3 is often necessary.\n",
    "#    A common rule of thumb is sqrt(N) or log2(N), but max(2, ...) is safest minimum.\n",
    "safe_n_neighbors = max(2, min(15, n_samples - 1))\n",
    "if safe_n_neighbors == 0: # Avoid n_neighbors of 0 if n_samples is 1\n",
    "    safe_n_neighbors = 1 # Though UMAP would likely fail for n_samples=1 anyway\n",
    "\n",
    "# 2. n_components: Should be less than n_neighbors.\n",
    "#    If n_neighbors is small (e.g., 2 or 3), n_components should be 1 or 2.\n",
    "safe_n_components = min(5, safe_n_neighbors - 1)\n",
    "if safe_n_components < 1:\n",
    "    safe_n_components = 1 # Smallest possible output dimension\n",
    "\n",
    "# 3. Initialization Method: Crucial for avoiding the `eigsh` error.\n",
    "#    'spectral' is default and uses `eigsh`. 'random' avoids it.\n",
    "umap_init_method = 'random' # <--- MOST LIKELY FIX FOR THE TypeError\n",
    "\n",
    "print(f\"UMAP: n_samples={n_samples}, safe_n_neighbors={safe_n_neighbors}, safe_n_components={safe_n_components}, init='{umap_init_method}'\")"
   ],
   "id": "b6d770abbc224c3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP: n_samples=5, safe_n_neighbors=4, safe_n_components=3, init='random'\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T06:05:14.496159Z",
     "start_time": "2025-07-20T06:05:14.067732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "umap_model = umap.UMAP(\n",
    "    n_neighbors=safe_n_neighbors,\n",
    "    n_components=safe_n_components,\n",
    "    min_dist=0.0,    # Good for preserving local structure\n",
    "    metric='cosine', # Often works well with sentence embeddings\n",
    "    random_state=42, # For reproducibility\n",
    "    init=umap_init_method # Explicitly use 'random' initialization\n",
    ")\n",
    "\n",
    "# Initialize BERTopic with custom UMAP and HDBSCAN models\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,  # Custom UMAP model\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True,\n",
    "    language=\"english\"\n",
    ")\n",
    "\n",
    "\n"
   ],
   "id": "5539b9f62c1ff58e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 11:35:14,077 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n",
      "2025-07-20 11:35:14,303 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T06:07:26.219475Z",
     "start_time": "2025-07-20T06:07:25.785579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Fit the model\n",
    "topics, probs = topic_model.fit_transform(documents, embeddings)\n",
    "topic_model.save(\"my_topic_model\")  # ✅ now it includes fitted topics\n",
    "\n",
    "\n",
    "print(\"\\nBERTopic model fitted successfully with UMAP (adjusted for small dataset and random initialization).\")\n",
    "print(f\"Number of topics found: {len(topic_model.get_topics())}\")\n",
    "\n",
    "# Optional: Further exploration\n",
    "# print(\"Topic-document probabilities sample:\")\n",
    "# print(probs[:5]) # Print first 5 probability arrays\n",
    "# print(\"Document topics sample:\")\n",
    "# print(topics[:10]) # Print topics for first 10 documents\n",
    "# print(\"Top 5 topics:\")\n",
    "# print(topic_model.get_topics(n=5))"
   ],
   "id": "d8e2d20b6c7c0cb1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 11:37:25,795 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-07-20 11:37:25,810 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-07-20 11:37:25,810 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-07-20 11:37:25,824 - BERTopic - Cluster - Completed ✓\n",
      "2025-07-20 11:37:25,828 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-07-20 11:37:25,858 - BERTopic - Representation - Completed ✓\n",
      "2025-07-20 11:37:25,920 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERTopic model fitted successfully with UMAP (adjusted for small dataset and random initialization).\n",
      "Number of topics found: 2\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T06:07:29.538465Z",
     "start_time": "2025-07-20T06:07:29.506678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get topic representations (top words for each topic)\n",
    "topics_info = topic_model.get_topic_info()\n",
    "\n",
    "# Create a dictionary mapping topic ID → human-readable name\n",
    "topic_id_to_name = {}\n",
    "for _, row in topics_info.iterrows():\n",
    "    topic_id = row[\"Topic\"]\n",
    "    name = f\"Topic {topic_id}: \" + row[\"Name\"] if \"Name\" in row else f\"Topic {topic_id}: \" + row[\"Representation\"]\n",
    "    topic_id_to_name[topic_id] = name\n",
    "\n",
    "# Now replace numerical topic labels with names\n",
    "named_topics = [topic_id_to_name[tid] for tid in topics]\n",
    "\n",
    "# Add back to DataFrame for convenience\n",
    "df[\"Named_Topic\"] = named_topics\n",
    "\n",
    "# (Optional) Save to CSV for review\n",
    "df.to_csv(\"documents_with_named_topics.csv\", index=False)\n",
    "\n",
    "print(\"Saved topic-labeled documents to documents_with_named_topics.csv\")\n"
   ],
   "id": "77e0cd9529d5ecc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved topic-labeled documents to documents_with_named_topics.csv\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f63f777bacced481"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
